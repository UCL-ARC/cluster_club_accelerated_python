{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bf5bdb-cb81-4951-b1e3-a10d2d641dea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Memory layouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041b8e7-1f01-4a5b-b589-d8a8f4f4b9dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can imagine memory as a linear collection of consecutive memory addresses (each one representing one byte).\n",
    "\n",
    "\n",
    "![Byte array in memory](./img/byte_array.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2403c-45aa-4df8-9852-580d26b953e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "The key toe fficient data representations is to order data spatially local in memory. This means that the data we want to work on next should be as close to our current data as possible. The reason is that memory accesses in modern computers are extremely expensive compared to actual computations. In order to alleviate this problem all modern CPUs rely on sophisticated caches that try to read data ahead of time from the memory. This works only if the next pieces of data are close to the data that we are currently working on.\n",
    "\n",
    "Standard Python list types do not guarantee this locality. List elements can be at very different memory addresses, making standard lists are other base Python types unsuitable for numerical operations. What we require is a buffer type that guarantees us a chunk of consecutive addresses in the system memory.\n",
    "\n",
    "What happens if we have a matrix? Consider a 2 x 2 matrix\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & 2\\\\ 3 & 4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We have two ways of ordering this matrix across the memory band\n",
    "\n",
    "* **C-Style ordering:** This aligns the matrix row by row in memory. Hence, our memory buffer will have four elements that read\n",
    "\n",
    "$$\n",
    "1, 2, 3, 4\n",
    "$$\n",
    "\n",
    "* **Fortran Style ordering:** This aligns the matrix column by column in memory. Our memory buffer will now have four elements that read\n",
    "\n",
    "$$\n",
    "1, 3, 2, 4\n",
    "$$\n",
    "\n",
    "Both memory layout styles are used across scientific computing, and it is important to know what the assumed layout in a given numerical library is. Ignoring data layouts leads to inefficiency if code has to translate on the fly between the layouts, or even bugs if the layout differences are ignored by a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8d8e2222",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f61ffa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f61d15-1272-4ed4-9163-666e089e51d3",
   "metadata": {},
   "source": [
    "Let's create two identical NxN arrays, but store them into memory with C and Fortran style orderings. For the purpose of computation, the arrays are element-wise equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c57844de-7263-491c-b6c2-11df24131819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A == Ac is True\n",
      "A == Af is True\n",
      "Ac == Af is True\n"
     ]
    }
   ],
   "source": [
    "A = np.random.rand(N,N)\n",
    "Ac = np.array(A, order = 'C')\n",
    "Af = np.array(A, order = 'F')\n",
    "B = np.zeros(N)\n",
    "\n",
    "print ('A == Ac is', (A == Ac).all())\n",
    "print ('A == Af is', (A == Af).all())\n",
    "print ('Ac == Af is', (Ac == Af).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5657308-0edb-42e9-b335-341598691752",
   "metadata": {},
   "source": [
    "So what is the difference? The strides attribute tells us how many bytes in memory we have to stride to reach the next element *per dimension*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "68e6a22d-9f25-42a4-ab13-67b9f872bfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strides of Ac (80000, 8)\n",
      "Strides of Af (8, 80000)\n"
     ]
    }
   ],
   "source": [
    "print('Strides of Ac', Ac.strides)\n",
    "print('Strides of Af', Af.strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed9952-5d19-4a36-bfe2-2edd377654b3",
   "metadata": {},
   "source": [
    "The stride makes a difference when we have to traverse through values of the array because of how the CPU loads data from memory into its registers. Operations are much faster when we can access our data with *unit stride*, that is we are accessing items that are contiguous in memory. For example, reshaping the array is very fast with C ordering (unit stride) and very slow with F ordering (N stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dc983948-ff47-4ca5-87dc-85ea1587fca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 18 µs, total: 30 µs\n",
      "Wall time: 28.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17424391],\n",
       "       [0.76032097],\n",
       "       [0.81354533],\n",
       "       ...,\n",
       "       [0.32279642],\n",
       "       [0.69398405],\n",
       "       [0.28208163]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Ac.reshape(N*N,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ed19432c-7411-4e7a-92c0-49cb4e596767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 945 ms, sys: 199 ms, total: 1.14 s\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17424391],\n",
       "       [0.76032097],\n",
       "       [0.81354533],\n",
       "       ...,\n",
       "       [0.32279642],\n",
       "       [0.69398405],\n",
       "       [0.28208163]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Af.reshape(N*N,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b88734-2d41-40bc-8f77-22c072e24600",
   "metadata": {},
   "source": [
    "So why care about this? C ordering is the default so just don't touch it and the code will be fast, right? Not quite. It depends on how you are accessing the elements of the array. Of course numpy functions will be optimized for the default ordering, but if you are doing more complex memory accesses it can make a big difference. This is also important to keep in mind if you are interfacing to other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6ff19686-6296-4e33-ab72-9b66da45b0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 114 ms, sys: 3.23 ms, total: 118 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in np.arange(N):\n",
    "    c[i] = np.sum(Ac[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b3cbf16a-7500-4acb-8de7-b5e0e180fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 854 ms, sys: 7.25 ms, total: 861 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in np.arange(N):\n",
    "    c[i] = np.sum(Af[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c15aacb8-b704-4688-a9a3-873fa6c5f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 888 ms, sys: 8.6 ms, total: 897 ms\n",
      "Wall time: 920 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in np.arange(N):\n",
    "    c[i] = np.sum(Ac[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "41a1cd80-40c6-4770-9523-4b09ac0675ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 119 ms, sys: 2.95 ms, total: 122 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in np.arange(N):\n",
    "    c[i] = np.sum(Af[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334a37c-bec7-4187-b65a-e578c45d5289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
